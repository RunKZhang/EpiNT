{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using EpiNT for Feature Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Short Introduction \n",
    "\n",
    "Traditional machine learning framework needs manual feature engineering, which involves constructing and extracting meaningful features for classification. This process requires expert knowledge, and deep understanding of the data.\n",
    "\n",
    "In this notebook, we illustrate how EpiNT can act as feature extractor, that extracts features (embeddings) for machine learning classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Configurations and EpiNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import h5py\n",
    "\n",
    "from yaml import CLoader as Loader\n",
    "from yaml import load\n",
    "from argparse import Namespace\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from epint.model.EpiNTModel import EpiNT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yaml(file):\n",
    "    with open(file, 'r') as f:\n",
    "        return load(f, Loader=Loader)\n",
    "\n",
    "def merge_config(base_config, new_config):\n",
    "    for key, value in new_config.items():\n",
    "        base_config[key] = value\n",
    "    return base_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patch_len': 256, 'stride_len': 256, 'sequence_len': 3072, 'dropout': 0.1, 'cls_token': True, 'downstream_dataset': '/home/ZRK/ZRK_ssd2/ZRK/Engineering_Server/Epileptogenic/dataset/downstream_wo_sfreq_equal_cpres_chn.hdf5', 'RESULTS_DIR': '/home/ZRK/sda_data/zrkdata/Epileptogenic_Results/', 'experiment_name': 'linear_probing', 'seizure_task': 'hfo_ied_detec2', 'model_name': 'EpiNT', 'patch_mask': False, 'mask_ratio': 0, 'head_dropout': 0.1, 'task': 'classification', 'd_model': 512, 'dim_feedforward': 2048, 'num_heads': 8, 'num_layers': 6, 'codebook_dim': 64, 'codebook_size': 256, 'num_quantizer': 1, 'optimizer_name': 'AdamW', 'lr_scheduler_type': 'onecyclelr', 'pct_start': 0.3, 'init_lr': 0.0001, 'three_phase': False, 'weight_decay': 0.05, 'num_workers': 4, 'max_norm': 5.0, 'max_epoch': 10, 'train_ratio': 0.7, 'train_batch_size': 1024, 'debug': True, 'seed': 666, 'run_name': '20241226_015111'}\n"
     ]
    }
   ],
   "source": [
    "finetune_config_path = '../configs/finetune_configs.yaml'\n",
    "default_config_path = '../configs/default.yaml'\n",
    "\n",
    "finetune_config = read_yaml(finetune_config_path)\n",
    "default_config = read_yaml(default_config_path)\n",
    "merged_config = merge_config(default_config, finetune_config)\n",
    "\n",
    "# convert config to arguments\n",
    "args = Namespace(**merged_config)\n",
    "print(merged_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['head.weight', 'head.bias'], unexpected_keys=['embed.mask_encoding'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EpiNT(args)\n",
    "\n",
    "# load finetune weights\n",
    "finetune_weights_path = '../weights/representations.bin'\n",
    "finetune_weights = torch.load(finetune_weights_path)\n",
    "model.load_state_dict(finetune_weights, strict=False)\n",
    "\n",
    "# Since we use an additional classifier, the original head is omitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load Dataset\n",
    "\n",
    "We consruct a sample dataset using MAYO dataset. We select 1000 balanced samples (500 negatives v.s. 500 positives) for training, and 100 balanced samples (50 negatives v.s. 50 positives) for evaluating the logistic regression classifier.\n",
    "\n",
    "We select logistic regression classifier due to its simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: torch.Size([1000, 3072]), Train labels shape: torch.Size([1000])\n",
      "Test data shape: torch.Size([100, 3072]), Test labels shape: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "sample_data_path = '../dataset/sample_data.hdf5'\n",
    "h5file = h5py.File(sample_data_path, 'r')\n",
    "\n",
    "train_data = h5file['train_data'][:]\n",
    "train_labels = h5file['train_labels'][:]\n",
    "test_data = h5file['test_data'][:]\n",
    "test_labels = h5file['test_labels'][:]\n",
    "\n",
    "train_data = torch.tensor(train_data, dtype=torch.float32).squeeze(1)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.long)\n",
    "test_data = torch.tensor(test_data, dtype=torch.float32).squeeze(1)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "print(f'Train data shape: {train_data.shape}, Train labels shape: {train_labels.shape}')\n",
    "print(f'Test data shape: {test_data.shape}, Test labels shape: {test_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We only need EpiNT to work in evaluation mode for feature extraction.\n",
    "The [cls] token is used to represent the entire sequence.\n",
    "\"\"\"\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    _, train_cls = model(train_data)\n",
    "    _, test_cls = model(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.915\n",
      "Test Accuracy: 0.85\n",
      "Train Confusion Matrix:\n",
      "[[456  44]\n",
      " [ 41 459]]\n",
      "Test Confusion Matrix:\n",
      "[[41  9]\n",
      " [ 6 44]]\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.85        50\n",
      "           1       0.83      0.88      0.85        50\n",
      "\n",
      "    accuracy                           0.85       100\n",
      "   macro avg       0.85      0.85      0.85       100\n",
      "weighted avg       0.85      0.85      0.85       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train logistic regression\n",
    "train_cls_flat = train_cls.squeeze(1).numpy()\n",
    "test_cls_flat = test_cls.squeeze(1).numpy()\n",
    "\n",
    "# Train logistic regression\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(train_cls_flat, train_labels.numpy())\n",
    "\n",
    "# Evaluate the classifier\n",
    "train_accuracy = clf.score(train_cls_flat, train_labels.numpy())\n",
    "test_accuracy = clf.score(test_cls_flat, test_labels.numpy())\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Generate confusion matrices\n",
    "train_cm = confusion_matrix(train_labels.numpy(), clf.predict(train_cls_flat))\n",
    "test_cm = confusion_matrix(test_labels.numpy(), clf.predict(test_cls_flat))\n",
    "\n",
    "# Print confusion matrices\n",
    "print(\"Train Confusion Matrix:\")\n",
    "print(train_cm)\n",
    "print(\"Test Confusion Matrix:\")\n",
    "print(test_cm)\n",
    "\n",
    "# Print classification report for test data\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(test_labels.numpy(), clf.predict(test_cls_flat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results (confusion matrix and accuracy score) illustrate that the extracted features (embeddings) have good discrimination."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
